{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 15)\n",
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat  medv  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "# setting the path for Data from data/housing folder\n",
    "DATA_FILE_TRAIN = './data/Boston.csv'\n",
    "#setting the random seed \n",
    "np.random.seed(42)\n",
    "# Loading the dataset\n",
    "train_data = pd.read_csv(DATA_FILE_TRAIN)\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_1 = 101\n",
    "BATCH_SIZE_2 = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# To decide on the bin values\n",
    "print(train_data['medv'].max())\n",
    "print(train_data['medv'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat medv  \n",
      "0     15.3  396.90   4.98    0  \n",
      "1     17.8  396.90   9.14    0  \n",
      "2     17.8  392.83   4.03    1  \n",
      "3     18.7  394.63   2.94    1  \n",
      "4     18.7  396.90   5.33    1  \n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bins = [0,30,50]\n",
    "labels = [0,1]\n",
    "train_data['medv'] = pd.cut(train_data['medv'], bins=bins, labels=labels)\n",
    "print(train_data.head())\n",
    "print(len(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6bf9ac38e3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The target class ratio is {Counter(train_data['medv']) }\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"The target class ratio is {Counter(train_data['medv']) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = ['ID']\n",
    "categorical_features = ['chas'] \n",
    "target_feature = 'medv'\n",
    "\n",
    "dropped_cols = id_col+categorical_features\n",
    "train_data = train_data.drop(dropped_cols, axis=1)\n",
    "all_features = train_data.columns.tolist()  #this will not have 'chas' and 'ID'\n",
    "\n",
    "numerical_features = list(set(all_features)- set([target_feature]))\n",
    "#print(len(numerical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_inp = train_data[numerical_features]\n",
    "train_data_tar = train_data[target_feature]\n",
    "Trn_input,  Val_inp, Trn_target,Val_target = train_test_split(train_data_inp, train_data_tar, test_size=0.2,random_state=123)\n",
    "# Train_data has our training dataset and Valid_data has our validation dataset.\n",
    "Train_data = pd.concat([Trn_input, pd.DataFrame(Trn_target)], axis=1)\n",
    "Valid_data = pd.concat([Val_inp, pd.DataFrame(Val_target)], axis=1)\n",
    "print(Train_data.shape)\n",
    "print(Valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oversampdata(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.inp_data = torch.FloatTensor(data.values.astype('float')[:, :-1])\n",
    "        self.out_data = data.values[:, -1]\n",
    "        self.out_data = torch.FloatTensor(get_categorical(self.out_data).astype('float'))\n",
    "        print(self.out_data.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.inp_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #target = self.out_data[ind]\n",
    "        #data_val = self.data[index] [:-1]\n",
    "        return self.inp_data[index],self.out_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical(arr):\n",
    "    out_arr = np.zeros(((len(arr), 2)))\n",
    "    for i,val in enumerate(arr):\n",
    "        out_arr[i][int(val)] = 1\n",
    "    #print(np.argmax(out_arr, axis =1))\n",
    "    return out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation dataset \n",
    "train_dataset = oversampdata(Train_data)\n",
    "valid_dataset = oversampdata(Valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_1, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE_2, shuffle=True, **kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
